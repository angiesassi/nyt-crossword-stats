---
title: "NYT Crosswords Analysis"
author: "Angelina Sassi"
date: "5/11/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
ggplot2::theme_set(ggplot2::theme_minimal())
library(nlme)
library(lme4)
library(lmerTest)
library(visreg)
library(sjPlot)
library(sjmisc)
library(ggeffects)
library(gridExtra)
library(ggfortify)
library(gtsummary)
```

# Angie's NYT Crosswords Analysis

I've been playing the New York Times crossword consistently since July 2019, and I want to confirm my hypothesis that I'm improving over time. I downloaded my NYT Crossword data thanks to [this code developed by Matt Dodge (thanks, Matt!)](https://github.com/mattdodge/nyt-crossword-stats). In my first adventure with GitHub and Python, I added the variable `solve_date` to the CSV output using the code fork [https://github.com/angiesassi/nyt-crossword-stats](here). Props and many thanks to Ari and Ed for their Python assistance!

```{r}
#library(reticulate)
#source_python("fetch_puzzle_stats_as.py")
```

```{r}
library(tidyverse)
data <- read_csv("data.csv")

#remove dates with unsolved puzzles
data <- data %>% 
  filter(elapsed_seconds != 0) %>% 
  filter(solved == 1)

#adjust date format of solve_date
data$solve_date <- as.Date(data$solve_date, format = "%Y-%d-%m")

#check that the data are correct
data$solve_date[data$date == '2020-04-30']

#remove outliers (Thursday 2019-07-25 and Saturday 2019-09-14 (Rex Parker did it in 6:49, there's no way I beat him without copying someone else...))
data <- data[-c(5),]
data <- data[-c(55),]
```


```{r}
data$day <- factor(data$day, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))

ggplot(data, aes(x=day, y=elapsed_seconds, fill = day))+
  geom_boxplot()+
  labs(title = "NYT Crossword Solve Time in Seconds by Day of the Week", x = "Day of the Week", y="Solve Time (Seconds)")

knitr::kable(data %>% 
  group_by("Day of the Week" = day) %>% 
  summarize("Fastest Time (in min.)" = round(min(elapsed_seconds)/60,2), "Average Time" = round(mean(elapsed_seconds)/60,2), "Std. dev." = round(sd(elapsed_seconds)/60,2)))
```


```{r}
#add a "week" variable based on puzzle date
data_Mon <- data %>% 
  filter(day == "Mon") %>% 
  mutate(week = c(1:nrow(data %>% filter(day=="Mon"))))

data_Tue <- data %>% 
  filter(day == "Tue") %>% 
  mutate(week = c(1:nrow(data %>% filter(day=="Tue"))))

data_Wed <- data %>% 
  filter(day == "Wed") %>% 
  mutate(week = c(1:nrow(data %>% filter(day=="Wed"))))

data_Thu <- data %>% 
  filter(day == "Thu") %>% 
  mutate(week = c(1:nrow(data %>% filter(day=="Thu"))))

data_Fri <- data %>% 
  filter(day == "Fri") %>% 
  mutate(week = c(1:nrow(data %>% filter(day=="Fri"))))

data_Sat <- data %>% 
  filter(day == "Sat") %>% 
  mutate(week = c(1:nrow(data %>% filter(day=="Sat"))))

data_Sun <- data %>% 
  filter(day == "Sun") %>% 
  mutate(week = c(1:nrow(data %>% filter(day=="Sun"))))

data <- rbind(data_Mon, data_Tue, data_Wed, data_Thu, data_Fri, data_Sat, data_Sun)
```


```{r}
ggplot(data, aes(x=elapsed_seconds, fill = day))+
  geom_histogram()+
  facet_wrap(~day)+
  ggtitle("Histograms of Solve Time by Puzzle Day")

p1<-ggplot(data, aes(x=week, y=elapsed_seconds, color=day))+
  geom_line()+
  geom_smooth(method="lm", se=FALSE)+
  ggtitle("Solve Time by Puzzle Day over time (weeks)")

p1
```

Average solve time appears to decrease as the date the puzzle was published increases, with the sharpest decreases among Sunday puzzles.

# Modeling

## Simple linear model

```{r}
model1 <- lm(elapsed_seconds ~ week, data=data)
summary(model1)
```

## Random intercepts model + diagnostics

```{r}
model2 <- lmer(elapsed_seconds ~ week + (1|day), data=data)
summary(model2)

df <- data
df$res <- model2@resp$wtres

ggplot(df, aes(x=res))+
  geom_histogram()+
  xlab(expression(epsilon))+
  ggtitle("Histogram of Random Intercept Model Errors")

ggplot(df, aes(sample=res))+
  stat_qq()+
  geom_qq_line()+
  ggtitle("Q-Q Plot of Random Intercept Model Errors")

df$fitted <- fitted(model2)

ggplot(df, aes(x=fitted,y=res))+
  geom_point()+
  ylab(expression(epsilon))+
  ggtitle("Scatterplot of Residuals vs. Fitted")
```

## Random slopes and intercepts model

```{r}
model3 <- lmer(elapsed_seconds ~ week + (1+day|day), data=data)
summary(model3)
```

## Summary of Results (AIC and BIC)

```{r}
AIC(model1, model2, model3)
BIC(model1, model2, model3)
```

# Does ordering puzzles by the date I solved them make a difference in the goodness of fit?

```{r}
#sort by solved date
data <- data[order(data$solve_date),]

#add "week2" variable (chronological order of solved date)
data_Mon <- data %>% 
  filter(day == "Mon") %>% 
  mutate(week2 = c(1:nrow(data %>% filter(day=="Mon"))))

data_Tue <- data %>% 
  filter(day == "Tue") %>% 
  mutate(week2 = c(1:nrow(data %>% filter(day=="Tue"))))

data_Wed <- data %>% 
  filter(day == "Wed") %>% 
  mutate(week2 = c(1:nrow(data %>% filter(day=="Wed"))))

data_Thu <- data %>% 
  filter(day == "Thu") %>% 
  mutate(week2 = c(1:nrow(data %>% filter(day=="Thu"))))

data_Fri <- data %>% 
  filter(day == "Fri") %>% 
  mutate(week2 = c(1:nrow(data %>% filter(day=="Fri"))))

data_Sat <- data %>% 
  filter(day == "Sat") %>% 
  mutate(week2 = c(1:nrow(data %>% filter(day=="Sat"))))

data_Sun <- data %>% 
  filter(day == "Sun") %>% 
  mutate(week2 = c(1:nrow(data %>% filter(day=="Sun"))))

data2 <- rbind(data_Mon, data_Tue, data_Wed, data_Thu, data_Fri, data_Sat, data_Sun)

p2<-ggplot(data2, aes(x=week2, y=elapsed_seconds, color=day))+ 
  geom_line()+ 
  geom_smooth(method="lm", se=FALSE)+
  ggtitle("Solve Time by Puzzle Day over time (weeks)")

p1
p2
```

The two "week" variables don't appear to differ that much. Let's see whether models based on the `week2` variable have better fits.

## Simple linear model

```{r}
model4 <- lm(elapsed_seconds ~ week2, data=data2)
summary(model4)
```

## Random intercepts model

```{r}
model5 <- lmer(elapsed_seconds ~ week2 + (1|day), data=data2)
summary(model5)

df3 <- data2
df3$res <- model5@resp$wtres

ggplot(df3, aes(x=res))+
  geom_histogram()+
  xlab(expression(epsilon))+
  ggtitle("Histogram of Random Intercept Model Errors")

ggplot(df3, aes(sample=res))+
  stat_qq()+
  geom_qq_line()+
  ggtitle("Q-Q Plot of Random Intercept Model Errors")

df3$fitted <- fitted(model5)

ggplot(df3, aes(x=fitted,y=res))+
  geom_point()+
  ylab(expression(epsilon))+
  ggtitle("Scatterplot of Residuals vs. Fitted")
```

## Random slopes and intercepts model

```{r}
model6 <- lmer(elapsed_seconds ~ week2 + (1+day|day), data=data2)
summary(model6)
```

## Summary of All Results (AIC and BIC)

```{r}
AIC(model1, model2, model3, model4, model5, model6)
BIC(model1, model2, model3, model4, model5, model6)

summary(model5)

```

Model 5 -- random intercepts with solved week as the explanatory variable -- has the best fit. According to Model 5, I decrease my average puzzle solve time by -11.734 seconds each week.

# Models for each day of the week because I'm compulsive

```{r}
fitmon <- lm(elapsed_seconds ~ week2, data=filter(data2, day=="Mon"))
fittue <- lm(elapsed_seconds ~ week2, data=filter(data2, day=="Tue"))
fitwed <- lm(elapsed_seconds ~ week2, data=filter(data2, day=="Wed"))
fitthu <- lm(elapsed_seconds ~ week2, data=filter(data2, day=="Thu"))
fitfri <- lm(elapsed_seconds ~ week2, data=filter(data2, day=="Fri"))
fitsat <- lm(elapsed_seconds ~ week2, data=filter(data2, day=="Sat"))
fitsun <- lm(elapsed_seconds ~ week2, data=filter(data2, day=="Sun"))

tbl_mon <- tbl_regression(fitmon, intercept=TRUE)
tbl_tue <- tbl_regression(fittue, intercept=TRUE)
tbl_wed <- tbl_regression(fitwed, intercept=TRUE)
tbl_thu <- tbl_regression(fitthu, intercept=TRUE)
tbl_fri <- tbl_regression(fitfri, intercept=TRUE)
tbl_sat <- tbl_regression(fitsat, intercept=TRUE)
tbl_sun <- tbl_regression(fitsun, intercept=TRUE)

tbl_merge(tbls = list(tbl_mon, tbl_tue, tbl_wed, tbl_thu, tbl_fri, tbl_sat, tbl_sun), tab_spanner=c("**Mon**", "**Tue**", "**Wed**", "**Thu**", "**Fri**", "**Sat**", "**Sun**"))
```
My largest improvement each week is -23 seconds for Sunday puzzles, followed by Wednesday and Saturday (Wednesday has a slightly tighter confidence interval).

### Visregs

```{r}
visreg(fitmon)
visreg(fittue)
visreg(fitwed)
visreg(fitthu)
visreg(fitfri)
visreg(fitsat)
visreg(fitsun)
```

### Linear Regression Diagnostics

```{r}
autoplot(fitmon)
autoplot(fittue)
autoplot(fitwed)
autoplot(fitthu)
autoplot(fitfri)
autoplot(fitsat)
autoplot(fitsun)
```

